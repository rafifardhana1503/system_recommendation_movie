# -*- coding: utf-8 -*-
"""sistem rekomendasi movie_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MijkAc70GYUkASpFcbxamVs0IwHEAZfU

# Business Understanding

Dengan semakin banyaknya konten yang tersedia di platform streaming film, pengguna dihadapkan pada pilihan yang sangat beragam. Tanpa bantuan sistem yang tepat, pengguna mungkin kesulitan menemukan konten yang sesuai dengan preferensi mereka, yang dapat berdampak pada pengalaman pengguna (user experience) dan keterlibatan mereka dengan platform. Dari sudut pandang bisnis, menampilkan konten yang relevan secara konsisten dapat meningkatkan waktu tayang pengguna (watch time), retensi pelanggan, dan pada akhirnya meningkatkan pendapatan melalui langganan yang lebih lama atau konsumsi konten berbayar yang lebih banyak.

**Problem Statements**
- Bagaimana solusi bagi pengguna agar tidak kesulitan dalam menemukan konten film sesuai dengan preferensi mereka pada platform streaming?  
- Bagaimana memberikan suatu pertimbangan bagi pengguna untuk bertahan dalam menggunakan platform streaming?

**Goals**
- Mengembangkan sistem rekomendasi film berbasis content-based filtering.
- Memberikan output top-N rekomendasi film yang mirip dengan film yang dipilih pengguna.

**Solution statements**
- Menggunakan pendekatan **Content-Based Filtering**, hal ini dilakukan dengan memanfaatkan deskripsi film, genre, keywords, aktor, dan sutradara sebagai fitur konten. Kemiripan antar film akan diukur menggunakan algoritma Term Frequency-Inverse Document Frequency (TF-IDF) dan Cosine Similarity

# Data Understanding

Dataset yang digunakan merupakan dataset yang berisikan informasi detail mengenai berbagai film, termasuk judul, tanggal rilis, genre, sinopsis, aktor, sutradara, rating, dan lain-lain. Dataset ini diperoleh dari Kaggle: [TMDB 5000 Movie Dataset](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata)

## Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

nltk.download('punkt_tab')
nltk.download('stopwords')
nltk.download('wordnet')

import warnings
warnings.filterwarnings('ignore')

"""## Data Loading"""

df_movies = pd.read_csv("/content/tmdb_5000_movies.csv")
df_credits = pd.read_csv("/content/tmdb_5000_credits.csv")

"""## Exploratory Data Analysis

Dalam Exploratory Data Analysis (EDA) ini akan dilakukan dua tahap analisis, yaitu:
- Univariate Analysis (menganalisis masing-masing informasi dari dataset)
- Multivariate Analysis (menganalisis dua atau lebih informasi dari dataset)

### Univariate Analysis

1. Movies Dataset
"""

# Menampilkan dataset movies
df_movies

df_movies.info()

print("Banyak judul film:", len(df_movies.title.unique()))

"""Movie Dataset (4803 x 20):
- Terdapat missing value pada kolom `homepage`, `overview`, `release_date`, `runtime`, `tagline`
- Memiliki kombinasi tipe data yaitu int64, object, float64

Banyaknya judul film pada dataset berjumlah 4800 film, hal ini menandakan adanya indikasi duplikasi data atau missing value, sebab maksimal baris data pada kolom "title" berjumlah 4803 judul
"""

# Distribusi Vote Average
sns.histplot(df_movies['vote_average'], bins=20, kde=True, color='skyblue')
plt.title("Distribusi Vote Average")

"""Mayoritas film memiliki skor rata-rata (vote_average) antara 6 hingga 7, yang menunjukkan bahwa sebagian besar film dalam dataset ini memperoleh penilaian yang cukup baik dari penonton, meskipun tidak terlalu ekstrem. Sehingga film-film di dalam dataset ini kredibel

Distribusi rating ini juga menyerupai distribusi normal, mengindikasikan tidak adanya bias besar terhadap rating sangat rendah atau sangat tinggi.
"""

# Distribusi runtime film
sns.histplot(df_movies['runtime'].dropna(), bins=30, kde=True, color='skyblue')
plt.title("Distribusi Runtime Film")

"""Kebanyakan film berdurasi antara 90 hingga 120 menit, yang merupakan standar industri perfilman untuk film layar lebar. Namun, terdapat distribusi yang sedikit condong ke kanan (positively skewed), mengindikasikan adanya sejumlah kecil film berdurasi sangat panjang. Hal ini berkemungkinan target produksi film memang menyajikan film dengan durasi yang panjang

2. Credits Dataset
"""

# Menampilkan dataset credits
df_credits

df_credits.info()

"""Dari analisis di atas terdapat 4 kolom fitur dan 4803 baris pada dataset credits

### Multivariate Analysis
"""

# Melihat korelasi revenue vs budget
sns.scatterplot(data=df_movies, x='budget', y='revenue', alpha=0.6)
plt.title("Korelasi Budget vs Revenue")

"""Terdapat hubungan positif antara besarnya anggaran produksi film dengan pendapatan yang dihasilkan. Secara umum, film dengan anggaran lebih tinggi cenderung memiliki potensi meraih pendapatan lebih besar.

Namun, hubungan ini tidak bersifat linier, karena terdapat banyak penyimpangan di mana film dengan budget tinggi tidak selalu menghasilkan revenue tinggi. Sebaliknya, beberapa film berbudget rendah juga mampu menghasilkan pendapatan yang cukup besar, menunjukkan bahwa faktor kesuksesan film tidak hanya ditentukan oleh besarnya anggaran.
"""

# Melihat top 10 film dengan revenue tertinggi
top_revenue = df_movies[['title', 'revenue']].sort_values(by='revenue', ascending=False).head(10)
sns.barplot(data=top_revenue, y='title', x='revenue', palette='mako')

"""Film dengan revenue terbanyak yaitu Avatar, diikuti dengan Titanic dan The Avengers

# Data Preparation

Melakukan delapan tahap persiapan data, yaitu:
1. Rename Column
2. Drop Column
3. Merge Dataset
4. Selection Feature
5. Handling Missing Value dan Duplicate Data
6. Mengekstrak, Menggabungkan, dan Memberi Bobot List pada Isi Fitur
7. Normalisasi Teks (Cleaning Text) pada Isi Fitur
8. Vectorization TF-IDF

1. Rename Column
"""

# Mengubah nama kolom "movie_id" pada dataset credits menjadi "id"
df_credits = df_credits.rename(columns={"movie_id": "id"})
df_credits.info()

"""Hal ini bertujuan untuk menyelaraskan nama kolom id pada kedua dataset sebelum melakukan penggabungan (merge) dataset

2. Drop Column
"""

# Menghapus kolom title di dataset credits
df_credits = df_credits.drop(columns=['title'])

"""Melakukan drop (hapus) kolom "title" pada salah satu dataset untuk melakukan proses penggabungan agar kolom tidak double.

3. Merge Dataset
"""

# Menggabungkan dataset movies dan credits
df_merge = df_movies.merge(df_credits, on="id", how="left")
df_merge.head(1)

df_merge.info()

"""Menggabungkan kedua dataset menjadi dataset gabungan. Sebab kita membutuhkan beberapa fitur yang ada pada dataset credits, sehingga perlu dilakukan penggabungan (merge). Menghasilkan 22 kolom fitur pada dataset baru

4. Feature Selection
"""

# Seleksi fitur yang akan digunakan
df = df_merge[["id", "title", "genres", "keywords", "overview", "cast", "crew"]]
df.head(1)

"""Membuat dataset baru, dengan memilih fitur yang dibutuhkan saja. Kolom `id`, `title`, `genres`, `keywords`, `overview`, `cast`, dan `crew` dianggap penting sebab dapat merepresentasikan sebuah film

5. Handling Missing Value dan Duplicate Data
"""

df.isnull().sum()

df.dropna(inplace=True)
df.shape

print("Jumlah duplikasi data: ", df.duplicated().sum())

"""Terindikasi 3 missing value pada overview. Sebab gambaran umum dari film tidak kita ketahui, lebih baik baris missing value di hapus. Sehingga dataset terdiri dari 4800 baris dan 7 kolom penting

6. Mengekstrak, Menggabungkan, dan Memberi Bobot List pada Isi Fitur
"""

# Ekstrasi fitur
def extract_list(text):
    try:
        data = json.loads(text)
        return [item['name'] for item in data]
    except:
        return []

df['genres'] = df['genres'].apply(extract_list)
df['keywords'] = df['keywords'].apply(extract_list)
df['cast'] = df['cast'].apply(lambda x: extract_list(x)[:3]) # Ambil 3 aktor pertama
df['crew'] = df['crew'].apply(lambda x: [item['name'] for item in json.loads(x) if item['job'] == 'Director'][0] if any(item['job'] == 'Director' for item in json.loads(x)) else '')

df.head(1)

""" Beberapa kolom seperti genres, keywords, cast, dan crew berisi data dalam format JSON. Perlu dilakukan ekstraksi untuk mendapatkan daftar genre, kata kunci, nama aktor, dan nama sutradara."""

# Penggabungan Fitur Teks
def combine_features(row):
    overview = row['overview'].split() if isinstance(row['overview'], str) else []
    return ' '.join(overview + row['genres'] + row['keywords']*2 + row['cast']*3 + [row['crew']]*2)

df["tags"] = df.apply(combine_features, axis=1)

df.head(1)

"""Menggabungkan teks dari kolom overview, daftar genre, keywords, nama aktor, dan nama sutradara menjadi satu representasi teks (kolom "tags") untuk setiap film. Ini akan menjadi input utama untuk perhitungan kemiripan konten. Selain itu memberikan pembobotan pada fitur yang dianggap berpengaruh seperti fitur keywords, cast, dan crew"""

df_final = df[["id", "title", "tags"]]
df_final.head(1)

"""Membuat dataset final yang terdiri dari id film, judul film, dan representasi film (tags)

7. Normalisasi Teks List (Cleaning Text)
"""

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    text = text.lower() # Mengubah teks menjadi huruf kecil
    text = re.sub(r'[^a-zA-Z\s]', '', text) # Hilangkan karakter selain huruf dan spasi
    tokens = word_tokenize(text) # Tokenisasi (memecah kalimat jadi kata-kata)
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words] # Hilangkan stopwords & lemmatize
    return ' '.join(tokens) # Gabungkan kembali jadi string

df_final['tags'].apply(clean_text)

df_final['tags'] = df_final['tags'].apply(clean_text)
df_final.head()

"""Melakukan pembersihan (normalisasi) teks pada kolom "tags" sebelum masuk ke tahap modeling. Hal ini dilakukan agar model dapat mengolah representasi film untuk memperoleh hasil konten yang serupa
- Lowercase: Mengubah teks menjadi huruf kecil
- Re.sub: Menghilangkan karakter yang bukan spasi dan huruf
- Tokenisasi: Memecah teks menjadi unit-unit kata (token)
- Stopword Removal: Menghapus kata-kata umum dalam bahasa inggris yang tidak memiliki banyak informasi semantik
- Lemmatization: Mengembalikan kata-kata ke dalam bentuk dasarnya, misalnya stories menjadi story

8. Vectorization TF-IDF
"""

# TFIDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))
tfidf_matrix = tfidf_vectorizer.fit_transform(df_final['tags'])

"""Dilakukan terhadap fitur gabungan (overview, genres, keywords, cast, dan crew) yang telah digabung ke dalam kolom "tags" untuk mengubahnya menjadi vektor numerik agar dapat mengukur pentingnya sebuah kata dalam sebuah dokumen relatif terhadap kumpulan dokumen lainnya.

# Model Development & Result

## Modeling

Pada tahap ini, pengembangan model dilakukan dengan:
- Menghitung cosine similarity antara vektor TF-IDF dari fitur yang telah divektorkan terhadap film. Cosine similarity mengukur sudut antara dua vektor, dengan nilai 1 menunjukkan kemiripan sempurna dan nilai 0 menunjukkan tidak ada kemiripan
- Memberikan rekomendasi untuk film tertentu, sistem akan mencari film-film lain dengan nilai cosine similarity tertinggi terhadap film tersebut.
"""

# Cosine Similarity
cosine_sim = cosine_similarity(tfidf_matrix)

# Membuat reverse mapping dari indeks ke judul film
indices = pd.Series(df_final.index, index=df_final['title']).drop_duplicates()

# Fungsi untuk Mendapatkan Rekomendasi dengan Skor Cosine Similarity
def get_recommendations_with_scores(title, cosine_sim=cosine_sim, df=df_final, indices=indices):
    try:
        idx = indices[title]
    except KeyError:
        print(f"Film '{title}' tidak ditemukan dalam dataset.")
        return []

    # Dapatkan skor similaritas untuk film tersebut dengan semua film lain
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Urutkan film berdasarkan skor similaritas
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Dapatkan skor untuk 5 film yang paling mirip (tidak termasuk film itu sendiri)
    sim_scores = sim_scores[1:6]

    # Dapatkan indeks film dan skor similaritas
    movie_indices = [i[0] for i in sim_scores]
    similarity_scores = [i[1] for i in sim_scores]

    # Kembalikan DataFrame yang berisi judul dan skor similaritas
    df_recommendations = pd.DataFrame({'title': df_final['title'].iloc[movie_indices], 'similarity_score': similarity_scores})
    return df_recommendations

"""## Results"""

# Contoh penggunaan sistem rekomendasi 1 (satu) dengan skor
movie_title = "Iron Man"
recommendations_with_scores = get_recommendations_with_scores(movie_title)

print(f"\nRekomendasi film untuk '{movie_title}' dengan perhitungan Cosine Similarity:")
print(recommendations_with_scores)

# Contoh penggunaan sistem rekomendasi 2 (dua) dengan skor
movie_title = "The Fast and the Furious"
recommendations_with_scores = get_recommendations_with_scores(movie_title)

print(f"\nRekomendasi film untuk '{movie_title}' dengan Cosine Similarity:")
print(recommendations_with_scores)

"""# Evaluasi

#### **Metode Evaluasi**

Evaluasi ini berbasis relevansi rekomendasi yaitu Precision, dengan formula sebagai berikut\
`Precision = Jumlah rekomendasi film yang relevan / Jumlah item film yang direkomendasikan`
  
**Evaluasi penggunaan sistem rekomendasi 1 (satu):**\
**Film yang dipilih: Iron Man**
- Precision = 5/5
- Hasil Presisi Sistem Rekomendasi Film untuk Iron Man = 100%
- **Alasan Relevansi:**
  - Iron Man 2 → Sangat relevan (sekuel langsung)
  - Iron Man 3 → Sangat relevan (sekuel langsung)
  - Avengers: Age of Ultron → Relevan (Iron Man sangat berperan di film ini)
  - The Avengers → Relevan (Iron Man juga karakter utama)
  - Captain America: Civil War → Relevan (Iron Man juga memiliki peran utama di sini)

**Evaluasi penggunaan sistem rekomendasi 2 (dua)**\
**Film yang dipilih: The Fast and the Furious**
- Precision = 3/5
- Hasil Presisi Sistem Rekomendasi Film untuk The Fast and the Furious = 60%
- **Alasan Relevansi:**
  - Furious 7 → Relevan (satu franchise Fast and Furious)
  - 2 Fast 2 Furious → Relevan (sekuel Fast and Furious)
  - Fast Five → Relevan (seri kelima Fast and Furious)
  - Babylon A.D. → Kurang relevan (film aksi fiksi ilmiah, memang dibintangi Vin Diesel, tapi bukan bagian dari Fast and Furious)
  - xXx → Kurang relevan (juga film aksi Vin Diesel, tapi beda universe, bukan Fast and Furious)

Dengan menggunakan pendekatan Content-Based Filtering menggunakan TF-IDF dan Cosine Similarity dalam membangun sistem rekomendasi, diharapkan model ini dapat membantu memberikan dampak signifikan terhadap pemahaman bisnis dan potensi pertumbuhan platform streaming film.
"""